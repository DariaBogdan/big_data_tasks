[root@sandbox-hdp raj_ops]# sh ./spark_core/runner.sh run
SPARK_MAJOR_VERSION is set to 2, using Spark2
Namespace(bids_path='spark_core/bids.txt', exchange_rate_path='spark_core/exchange_rate.txt', motels_path='spark_core/motels.txt', result_path='spark_core/result')
18/07/31 13:32:01 INFO SparkContext: Running Spark version 2.3.0.2.6.5.0-292
18/07/31 13:32:01 INFO SparkContext: Submitted application: hw.py
18/07/31 13:32:01 INFO SecurityManager: Changing view acls to: root
18/07/31 13:32:01 INFO SecurityManager: Changing modify acls to: root
18/07/31 13:32:01 INFO SecurityManager: Changing view acls groups to: 
18/07/31 13:32:01 INFO SecurityManager: Changing modify acls groups to: 
18/07/31 13:32:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
18/07/31 13:32:01 INFO Utils: Successfully started service 'sparkDriver' on port 33145.
18/07/31 13:32:01 INFO SparkEnv: Registering MapOutputTracker
18/07/31 13:32:01 INFO SparkEnv: Registering BlockManagerMaster
18/07/31 13:32:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/07/31 13:32:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/07/31 13:32:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fb84a881-36d8-41f7-b3e3-211062b0aeeb
18/07/31 13:32:01 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/07/31 13:32:01 INFO SparkEnv: Registering OutputCommitCoordinator
18/07/31 13:32:02 INFO log: Logging initialized @2129ms
18/07/31 13:32:02 INFO Server: jetty-9.3.z-SNAPSHOT
18/07/31 13:32:02 INFO Server: Started @2215ms
18/07/31 13:32:02 INFO AbstractConnector: Started ServerConnector@69e604af{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
18/07/31 13:32:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1af45420{/jobs,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@523034b2{/jobs/json,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@373b8b48{/jobs/job,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5764c443{/jobs/job/json,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4a2ffb9{/stages,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6fa855ae{/stages/json,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7cd55d94{/stages/stage,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@338692fd{/stages/stage/json,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@65e940e4{/stages/pool,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7e542a98{/stages/pool/json,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@151c3f48{/storage,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@128a466c{/storage/json,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3dcbcab9{/storage/rdd,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@62143772{/storage/rdd/json,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1686a207{/environment,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@567f3f9d{/environment/json,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3502a9e9{/executors,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@766eb79c{/executors/json,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@55dbb5cc{/executors/threadDump,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7af7eb3d{/executors/threadDump/json,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5a1a586b{/static,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@52469d3a{/,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7cd8a041{/api,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@48e0916c{/jobs/job/kill,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3b37c783{/stages/stage/kill,null,AVAILABLE,@Spark}
18/07/31 13:32:02 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://sandbox-hdp.hortonworks.com:4040
18/07/31 13:32:02 INFO RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.18.0.2:8032
18/07/31 13:32:02 INFO Client: Requesting a new application from cluster with 1 NodeManagers
18/07/31 13:32:02 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (2250 MB per container)
18/07/31 13:32:02 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
18/07/31 13:32:02 INFO Client: Setting up container launch context for our AM
18/07/31 13:32:02 INFO Client: Setting up the launch environment for our AM container
18/07/31 13:32:02 INFO Client: Preparing resources for our AM container
18/07/31 13:32:03 INFO Client: Use hdfs cache file as spark.yarn.archive for HDP, hdfsCacheFile:hdfs://sandbox-hdp.hortonworks.com:8020/hdp/apps/2.6.5.0-292/spark2/spark2-hdp-yarn-archive.tar.gz
18/07/31 13:32:03 INFO Client: Source and destination file systems are the same. Not copying hdfs://sandbox-hdp.hortonworks.com:8020/hdp/apps/2.6.5.0-292/spark2/spark2-hdp-yarn-archive.tar.gz
18/07/31 13:32:03 INFO Client: Uploading resource file:/usr/hdp/2.6.5.0-292/spark2/python/lib/pyspark.zip -> hdfs://sandbox-hdp.hortonworks.com:8020/user/root/.sparkStaging/application_1533043542948_0001/pyspark.zip
18/07/31 13:32:04 INFO Client: Uploading resource file:/usr/hdp/2.6.5.0-292/spark2/python/lib/py4j-0.10.6-src.zip -> hdfs://sandbox-hdp.hortonworks.com:8020/user/root/.sparkStaging/application_1533043542948_0001/py4j-0.10.6-src.zip
18/07/31 13:32:05 INFO Client: Uploading resource file:/home/raj_ops/spark_core/classes.py -> hdfs://sandbox-hdp.hortonworks.com:8020/user/root/.sparkStaging/application_1533043542948_0001/classes.py
18/07/31 13:32:05 INFO Client: Uploading resource file:/tmp/spark-8ce5739a-c601-4487-97ab-4af6ba965ef0/__spark_conf__3070493299529999955.zip -> hdfs://sandbox-hdp.hortonworks.com:8020/user/root/.sparkStaging/application_1533043542948_0001/__spark_conf__.zip
18/07/31 13:32:05 INFO SecurityManager: Changing view acls to: root
18/07/31 13:32:05 INFO SecurityManager: Changing modify acls to: root
18/07/31 13:32:05 INFO SecurityManager: Changing view acls groups to: 
18/07/31 13:32:05 INFO SecurityManager: Changing modify acls groups to: 
18/07/31 13:32:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
18/07/31 13:32:05 INFO Client: Submitting application application_1533043542948_0001 to ResourceManager
18/07/31 13:32:05 INFO YarnClientImpl: Submitted application application_1533043542948_0001
18/07/31 13:32:05 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1533043542948_0001 and attemptId None
18/07/31 13:32:06 INFO Client: Application report for application_1533043542948_0001 (state: ACCEPTED)
18/07/31 13:32:06 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1533043925370
	 final status: UNDEFINED
	 tracking URL: http://sandbox-hdp.hortonworks.com:8088/proxy/application_1533043542948_0001/
	 user: root
18/07/31 13:32:07 INFO Client: Application report for application_1533043542948_0001 (state: ACCEPTED)
18/07/31 13:32:08 INFO Client: Application report for application_1533043542948_0001 (state: ACCEPTED)
18/07/31 13:32:09 INFO Client: Application report for application_1533043542948_0001 (state: ACCEPTED)
18/07/31 13:32:10 INFO Client: Application report for application_1533043542948_0001 (state: ACCEPTED)
18/07/31 13:32:11 INFO Client: Application report for application_1533043542948_0001 (state: ACCEPTED)
18/07/31 13:32:12 INFO Client: Application report for application_1533043542948_0001 (state: ACCEPTED)
18/07/31 13:32:13 INFO Client: Application report for application_1533043542948_0001 (state: ACCEPTED)
18/07/31 13:32:14 INFO Client: Application report for application_1533043542948_0001 (state: ACCEPTED)
18/07/31 13:32:15 INFO Client: Application report for application_1533043542948_0001 (state: ACCEPTED)
18/07/31 13:32:16 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> sandbox-hdp.hortonworks.com, PROXY_URI_BASES -> http://sandbox-hdp.hortonworks.com:8088/proxy/application_1533043542948_0001), /proxy/application_1533043542948_0001
18/07/31 13:32:16 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
18/07/31 13:32:16 INFO Client: Application report for application_1533043542948_0001 (state: ACCEPTED)
18/07/31 13:32:17 INFO Client: Application report for application_1533043542948_0001 (state: RUNNING)
18/07/31 13:32:17 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.18.0.2
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1533043925370
	 final status: UNDEFINED
	 tracking URL: http://sandbox-hdp.hortonworks.com:8088/proxy/application_1533043542948_0001/
	 user: root
18/07/31 13:32:17 INFO YarnClientSchedulerBackend: Application application_1533043542948_0001 has started running.
18/07/31 13:32:17 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
18/07/31 13:32:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42383.
18/07/31 13:32:17 INFO NettyBlockTransferService: Server created on sandbox-hdp.hortonworks.com:42383
18/07/31 13:32:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/07/31 13:32:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sandbox-hdp.hortonworks.com, 42383, None)
18/07/31 13:32:17 INFO BlockManagerMasterEndpoint: Registering block manager sandbox-hdp.hortonworks.com:42383 with 366.3 MB RAM, BlockManagerId(driver, sandbox-hdp.hortonworks.com, 42383, None)
18/07/31 13:32:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sandbox-hdp.hortonworks.com, 42383, None)
18/07/31 13:32:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sandbox-hdp.hortonworks.com, 42383, None)
18/07/31 13:32:18 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7c4aaae1{/metrics/json,null,AVAILABLE,@Spark}
18/07/31 13:32:18 INFO EventLoggingListener: Logging events to hdfs:/spark2-history/application_1533043542948_0001
18/07/31 13:32:23 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:40046) with ID 1
18/07/31 13:32:23 INFO BlockManagerMasterEndpoint: Registering block manager sandbox-hdp.hortonworks.com:41237 with 366.3 MB RAM, BlockManagerId(1, sandbox-hdp.hortonworks.com, 41237, None)
18/07/31 13:32:32 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)
18/07/31 13:32:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 360.1 KB, free 365.9 MB)
18/07/31 13:32:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.2 KB, free 365.9 MB)
18/07/31 13:32:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sandbox-hdp.hortonworks.com:42383 (size: 32.2 KB, free: 366.3 MB)
18/07/31 13:32:32 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
18/07/31 13:32:33 INFO FileInputFormat: Total input paths to process : 1
18/07/31 13:32:33 INFO NetworkTopology: Adding a new node: /default-rack/172.18.0.2:50010
18/07/31 13:32:33 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
18/07/31 13:32:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/07/31 13:32:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/07/31 13:32:33 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
18/07/31 13:32:33 INFO DAGScheduler: Registering RDD 3 (reduceByKey at /home/raj_ops/spark_core/hw.py:100)
18/07/31 13:32:33 INFO DAGScheduler: Got job 0 (runJob at SparkHadoopWriter.scala:78) with 2 output partitions
18/07/31 13:32:33 INFO DAGScheduler: Final stage: ResultStage 1 (runJob at SparkHadoopWriter.scala:78)
18/07/31 13:32:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
18/07/31 13:32:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
18/07/31 13:32:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /home/raj_ops/spark_core/hw.py:100), which has no missing parents
18/07/31 13:32:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KB, free 365.9 MB)
18/07/31 13:32:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.5 KB, free 365.9 MB)
18/07/31 13:32:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sandbox-hdp.hortonworks.com:42383 (size: 6.5 KB, free: 366.3 MB)
18/07/31 13:32:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
18/07/31 13:32:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /home/raj_ops/spark_core/hw.py:100) (first 15 tasks are for partitions Vector(0, 1))
18/07/31 13:32:33 INFO YarnScheduler: Adding task set 0.0 with 2 tasks
18/07/31 13:32:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 7916 bytes)
18/07/31 13:32:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sandbox-hdp.hortonworks.com:41237 (size: 6.5 KB, free: 366.3 MB)
18/07/31 13:32:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sandbox-hdp.hortonworks.com:41237 (size: 32.2 KB, free: 366.3 MB)
18/07/31 13:32:42 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, sandbox-hdp.hortonworks.com, executor 1, partition 1, RACK_LOCAL, 7916 bytes)
18/07/31 13:32:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8858 ms on sandbox-hdp.hortonworks.com (executor 1) (1/2)
18/07/31 13:32:49 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 7583 ms on sandbox-hdp.hortonworks.com (executor 1) (2/2)
18/07/31 13:32:49 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /home/raj_ops/spark_core/hw.py:100) finished in 16.493 s
18/07/31 13:32:49 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/07/31 13:32:49 INFO DAGScheduler: looking for newly runnable stages
18/07/31 13:32:49 INFO DAGScheduler: running: Set()
18/07/31 13:32:49 INFO DAGScheduler: waiting: Set(ResultStage 1)
18/07/31 13:32:49 INFO DAGScheduler: failed: Set()
18/07/31 13:32:49 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
18/07/31 13:32:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 97.3 KB, free 365.8 MB)
18/07/31 13:32:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 38.3 KB, free 365.8 MB)
18/07/31 13:32:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sandbox-hdp.hortonworks.com:42383 (size: 38.3 KB, free: 366.2 MB)
18/07/31 13:32:49 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
18/07/31 13:32:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
18/07/31 13:32:49 INFO YarnScheduler: Adding task set 1.0 with 2 tasks
18/07/31 13:32:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 7660 bytes)
18/07/31 13:32:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sandbox-hdp.hortonworks.com:41237 (size: 38.3 KB, free: 366.2 MB)
18/07/31 13:32:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:40046
18/07/31 13:32:50 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, sandbox-hdp.hortonworks.com, executor 1, partition 1, NODE_LOCAL, 7660 bytes)
18/07/31 13:32:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 552 ms on sandbox-hdp.hortonworks.com (executor 1) (1/2)
18/07/31 13:32:50 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 205 ms on sandbox-hdp.hortonworks.com (executor 1) (2/2)
18/07/31 13:32:50 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/07/31 13:32:50 INFO DAGScheduler: ResultStage 1 (runJob at SparkHadoopWriter.scala:78) finished in 0.780 s
18/07/31 13:32:50 INFO DAGScheduler: Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 17.478950 s
18/07/31 13:32:50 INFO SparkHadoopWriter: Job job_20180731133233_0008 committed.
18/07/31 13:32:50 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 360.2 KB, free 365.4 MB)
18/07/31 13:32:50 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.2 KB, free 365.4 MB)
18/07/31 13:32:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sandbox-hdp.hortonworks.com:42383 (size: 32.2 KB, free: 366.2 MB)
18/07/31 13:32:50 INFO SparkContext: Created broadcast 3 from textFile at NativeMethodAccessorImpl.java:0
18/07/31 13:32:50 INFO FileInputFormat: Total input paths to process : 1
18/07/31 13:32:50 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 360.2 KB, free 365.0 MB)
18/07/31 13:32:50 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.2 KB, free 365.0 MB)
18/07/31 13:32:50 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on sandbox-hdp.hortonworks.com:42383 (size: 32.2 KB, free: 366.2 MB)
18/07/31 13:32:50 INFO SparkContext: Created broadcast 4 from textFile at NativeMethodAccessorImpl.java:0
18/07/31 13:32:51 INFO FileInputFormat: Total input paths to process : 1
18/07/31 13:32:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/07/31 13:32:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
18/07/31 13:32:51 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
18/07/31 13:32:51 INFO DAGScheduler: Registering RDD 15 (leftOuterJoin at /home/raj_ops/spark_core/hw.py:121)
18/07/31 13:32:51 INFO DAGScheduler: Registering RDD 24 (leftOuterJoin at /home/raj_ops/spark_core/hw.py:149)
18/07/31 13:32:51 INFO DAGScheduler: Registering RDD 28 (reduceByKey at /home/raj_ops/spark_core/hw.py:157)
18/07/31 13:32:51 INFO DAGScheduler: Got job 1 (runJob at SparkHadoopWriter.scala:78) with 6 output partitions
18/07/31 13:32:51 INFO DAGScheduler: Final stage: ResultStage 5 (runJob at SparkHadoopWriter.scala:78)
18/07/31 13:32:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
18/07/31 13:32:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
18/07/31 13:32:51 INFO DAGScheduler: Submitting ShuffleMapStage 2 (PairwiseRDD[15] at leftOuterJoin at /home/raj_ops/spark_core/hw.py:121), which has no missing parents
18/07/31 13:32:51 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.0 KB, free 365.0 MB)
18/07/31 13:32:51 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.6 KB, free 365.0 MB)
18/07/31 13:32:51 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on sandbox-hdp.hortonworks.com:42383 (size: 7.6 KB, free: 366.2 MB)
18/07/31 13:32:51 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
18/07/31 13:32:51 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 2 (PairwiseRDD[15] at leftOuterJoin at /home/raj_ops/spark_core/hw.py:121) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
18/07/31 13:32:51 INFO YarnScheduler: Adding task set 2.0 with 4 tasks
18/07/31 13:32:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 8025 bytes)
18/07/31 13:32:51 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on sandbox-hdp.hortonworks.com:41237 (size: 7.6 KB, free: 366.2 MB)
18/07/31 13:33:20 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 5, sandbox-hdp.hortonworks.com, executor 1, partition 2, NODE_LOCAL, 8034 bytes)
18/07/31 13:33:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 29588 ms on sandbox-hdp.hortonworks.com (executor 1) (1/4)
18/07/31 13:33:20 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sandbox-hdp.hortonworks.com:41237 (size: 32.2 KB, free: 366.2 MB)
18/07/31 13:33:21 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 6, sandbox-hdp.hortonworks.com, executor 1, partition 3, NODE_LOCAL, 8034 bytes)
18/07/31 13:33:21 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 5) in 228 ms on sandbox-hdp.hortonworks.com (executor 1) (2/4)
18/07/31 13:33:21 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 6) in 116 ms on sandbox-hdp.hortonworks.com (executor 1) (3/4)
18/07/31 13:33:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 7, sandbox-hdp.hortonworks.com, executor 1, partition 1, RACK_LOCAL, 8025 bytes)
18/07/31 13:33:52 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 7) in 27327 ms on sandbox-hdp.hortonworks.com (executor 1) (4/4)
18/07/31 13:33:52 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/07/31 13:33:52 INFO DAGScheduler: ShuffleMapStage 2 (leftOuterJoin at /home/raj_ops/spark_core/hw.py:121) finished in 60.808 s
18/07/31 13:33:52 INFO DAGScheduler: looking for newly runnable stages
18/07/31 13:33:52 INFO DAGScheduler: running: Set()
18/07/31 13:33:52 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 3, ShuffleMapStage 4)
18/07/31 13:33:52 INFO DAGScheduler: failed: Set()
18/07/31 13:33:52 INFO DAGScheduler: Submitting ShuffleMapStage 3 (PairwiseRDD[24] at leftOuterJoin at /home/raj_ops/spark_core/hw.py:149), which has no missing parents
18/07/31 13:33:52 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 19.7 KB, free 365.0 MB)
18/07/31 13:33:52 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.4 KB, free 365.0 MB)
18/07/31 13:33:52 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on sandbox-hdp.hortonworks.com:42383 (size: 11.4 KB, free: 366.1 MB)
18/07/31 13:33:52 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
18/07/31 13:33:52 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 3 (PairwiseRDD[24] at leftOuterJoin at /home/raj_ops/spark_core/hw.py:149) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/07/31 13:33:52 INFO YarnScheduler: Adding task set 3.0 with 6 tasks
18/07/31 13:33:52 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 8, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 7758 bytes)
18/07/31 13:33:52 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on sandbox-hdp.hortonworks.com:41237 (size: 11.4 KB, free: 366.2 MB)
18/07/31 13:33:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.2:40046
18/07/31 13:34:33 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 9, sandbox-hdp.hortonworks.com, executor 1, partition 1, NODE_LOCAL, 7758 bytes)
18/07/31 13:34:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 8) in 41004 ms on sandbox-hdp.hortonworks.com (executor 1) (1/6)
18/07/31 13:35:13 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 10, sandbox-hdp.hortonworks.com, executor 1, partition 2, NODE_LOCAL, 7758 bytes)
18/07/31 13:35:13 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 9) in 40442 ms on sandbox-hdp.hortonworks.com (executor 1) (2/6)
18/07/31 13:35:53 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 11, sandbox-hdp.hortonworks.com, executor 1, partition 3, NODE_LOCAL, 7758 bytes)
18/07/31 13:35:53 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 10) in 39910 ms on sandbox-hdp.hortonworks.com (executor 1) (3/6)
18/07/31 13:36:32 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 12, sandbox-hdp.hortonworks.com, executor 1, partition 4, NODE_LOCAL, 8027 bytes)
18/07/31 13:36:32 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 11) in 39211 ms on sandbox-hdp.hortonworks.com (executor 1) (4/6)
18/07/31 13:36:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on sandbox-hdp.hortonworks.com:41237 (size: 32.2 KB, free: 366.1 MB)
18/07/31 13:36:32 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 13, sandbox-hdp.hortonworks.com, executor 1, partition 5, NODE_LOCAL, 8027 bytes)
18/07/31 13:36:32 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 12) in 160 ms on sandbox-hdp.hortonworks.com (executor 1) (5/6)
18/07/31 13:36:32 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 13) in 89 ms on sandbox-hdp.hortonworks.com (executor 1) (6/6)
18/07/31 13:36:32 INFO YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/07/31 13:36:32 INFO DAGScheduler: ShuffleMapStage 3 (leftOuterJoin at /home/raj_ops/spark_core/hw.py:149) finished in 160.820 s
18/07/31 13:36:32 INFO DAGScheduler: looking for newly runnable stages
18/07/31 13:36:32 INFO DAGScheduler: running: Set()
18/07/31 13:36:32 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 4)
18/07/31 13:36:32 INFO DAGScheduler: failed: Set()
18/07/31 13:36:32 INFO DAGScheduler: Submitting ShuffleMapStage 4 (PairwiseRDD[28] at reduceByKey at /home/raj_ops/spark_core/hw.py:157), which has no missing parents
18/07/31 13:36:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.6 KB, free 364.9 MB)
18/07/31 13:36:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.7 KB, free 364.9 MB)
18/07/31 13:36:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on sandbox-hdp.hortonworks.com:42383 (size: 7.7 KB, free: 366.1 MB)
18/07/31 13:36:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1039
18/07/31 13:36:32 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 4 (PairwiseRDD[28] at reduceByKey at /home/raj_ops/spark_core/hw.py:157) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/07/31 13:36:32 INFO YarnScheduler: Adding task set 4.0 with 6 tasks
18/07/31 13:36:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 14, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 7649 bytes)
18/07/31 13:36:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on sandbox-hdp.hortonworks.com:41237 (size: 7.7 KB, free: 366.1 MB)
18/07/31 13:36:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:40046
18/07/31 13:36:58 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 15, sandbox-hdp.hortonworks.com, executor 1, partition 1, NODE_LOCAL, 7649 bytes)
18/07/31 13:36:58 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 14) in 25786 ms on sandbox-hdp.hortonworks.com (executor 1) (1/6)
18/07/31 13:37:29 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 16, sandbox-hdp.hortonworks.com, executor 1, partition 2, NODE_LOCAL, 7649 bytes)
18/07/31 13:37:29 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 15) in 30678 ms on sandbox-hdp.hortonworks.com (executor 1) (2/6)
18/07/31 13:37:58 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 17, sandbox-hdp.hortonworks.com, executor 1, partition 3, NODE_LOCAL, 7649 bytes)
18/07/31 13:37:58 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 16) in 29070 ms on sandbox-hdp.hortonworks.com (executor 1) (3/6)
18/07/31 13:38:27 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 18, sandbox-hdp.hortonworks.com, executor 1, partition 4, NODE_LOCAL, 7649 bytes)
18/07/31 13:38:27 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 17) in 29113 ms on sandbox-hdp.hortonworks.com (executor 1) (4/6)
18/07/31 13:38:58 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 19, sandbox-hdp.hortonworks.com, executor 1, partition 5, NODE_LOCAL, 7649 bytes)
18/07/31 13:38:58 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 18) in 30691 ms on sandbox-hdp.hortonworks.com (executor 1) (5/6)
18/07/31 13:39:28 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 19) in 30327 ms on sandbox-hdp.hortonworks.com (executor 1) (6/6)
18/07/31 13:39:28 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/07/31 13:39:28 INFO DAGScheduler: ShuffleMapStage 4 (reduceByKey at /home/raj_ops/spark_core/hw.py:157) finished in 175.600 s
18/07/31 13:39:28 INFO DAGScheduler: looking for newly runnable stages
18/07/31 13:39:28 INFO DAGScheduler: running: Set()
18/07/31 13:39:28 INFO DAGScheduler: waiting: Set(ResultStage 5)
18/07/31 13:39:28 INFO DAGScheduler: failed: Set()
18/07/31 13:39:28 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[33] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
18/07/31 13:39:28 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 97.5 KB, free 364.8 MB)
18/07/31 13:39:28 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 38.5 KB, free 364.8 MB)
18/07/31 13:39:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on sandbox-hdp.hortonworks.com:42383 (size: 38.5 KB, free: 366.1 MB)
18/07/31 13:39:28 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1039
18/07/31 13:39:28 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 5 (MapPartitionsRDD[33] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
18/07/31 13:39:28 INFO YarnScheduler: Adding task set 5.0 with 6 tasks
18/07/31 13:39:28 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 20, sandbox-hdp.hortonworks.com, executor 1, partition 0, NODE_LOCAL, 7660 bytes)
18/07/31 13:39:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on sandbox-hdp.hortonworks.com:41237 (size: 38.5 KB, free: 366.1 MB)
18/07/31 13:39:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:40046
18/07/31 13:39:33 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 21, sandbox-hdp.hortonworks.com, executor 1, partition 1, NODE_LOCAL, 7660 bytes)
18/07/31 13:39:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 20) in 4645 ms on sandbox-hdp.hortonworks.com (executor 1) (1/6)
18/07/31 13:39:49 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 22, sandbox-hdp.hortonworks.com, executor 1, partition 2, NODE_LOCAL, 7660 bytes)
18/07/31 13:39:49 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 21) in 16077 ms on sandbox-hdp.hortonworks.com (executor 1) (2/6)
18/07/31 13:39:53 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 23, sandbox-hdp.hortonworks.com, executor 1, partition 3, NODE_LOCAL, 7660 bytes)
18/07/31 13:39:53 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 22) in 4427 ms on sandbox-hdp.hortonworks.com (executor 1) (3/6)
18/07/31 13:40:08 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 24, sandbox-hdp.hortonworks.com, executor 1, partition 4, NODE_LOCAL, 7660 bytes)
18/07/31 13:40:08 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 23) in 15300 ms on sandbox-hdp.hortonworks.com (executor 1) (4/6)
18/07/31 13:40:13 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 25, sandbox-hdp.hortonworks.com, executor 1, partition 5, NODE_LOCAL, 7660 bytes)
18/07/31 13:40:13 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 24) in 4612 ms on sandbox-hdp.hortonworks.com (executor 1) (5/6)
18/07/31 13:40:29 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 25) in 16319 ms on sandbox-hdp.hortonworks.com (executor 1) (6/6)
18/07/31 13:40:29 INFO YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/07/31 13:40:29 INFO DAGScheduler: ResultStage 5 (runJob at SparkHadoopWriter.scala:78) finished in 61.395 s
18/07/31 13:40:29 INFO DAGScheduler: Job 1 finished: runJob at SparkHadoopWriter.scala:78, took 458.654085 s
18/07/31 13:40:29 INFO ContextCleaner: Cleaned accumulator 59
18/07/31 13:40:29 INFO ContextCleaner: Cleaned accumulator 146
18/07/31 13:40:29 INFO ContextCleaner: Cleaned accumulator 48
18/07/31 13:40:29 INFO ContextCleaner: Cleaned accumulator 95
18/07/31 13:40:29 INFO ContextCleaner: Cleaned accumulator 106
18/07/31 13:40:29 INFO ContextCleaner: Cleaned accumulator 127
18/07/31 13:40:29 INFO ContextCleaner: Cleaned accumulator 109
18/07/31 13:40:29 INFO BlockManagerInfo: Removed broadcast_8_piece0 on sandbox-hdp.hortonworks.com:42383 in memory (size: 38.5 KB, free: 366.1 MB)
18/07/31 13:40:30 INFO SparkHadoopWriter: Job job_20180731133251_0033 committed.
18/07/31 13:40:30 INFO BlockManagerInfo: Removed broadcast_8_piece0 on sandbox-hdp.hortonworks.com:41237 in memory (size: 38.5 KB, free: 366.1 MB)
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 72
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 37
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 65
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 23
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 3
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 17
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 50
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 96
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 44
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 34
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 28
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 20
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 66
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 78
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 142
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 84
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 33
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 148
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 4
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 29
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 15
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 140
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 130
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 9
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 69
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 77
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 102
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 18
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 110
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 88
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 19
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 35
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 1
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 62
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 111
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 30
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 79
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 56
18/07/31 13:40:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on sandbox-hdp.hortonworks.com:42383 in memory (size: 6.5 KB, free: 366.1 MB)
18/07/31 13:40:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on sandbox-hdp.hortonworks.com:41237 in memory (size: 6.5 KB, free: 366.1 MB)
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 124
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 100
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 51
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 82
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 149
18/07/31 13:40:30 INFO BlockManagerInfo: Removed broadcast_2_piece0 on sandbox-hdp.hortonworks.com:42383 in memory (size: 38.3 KB, free: 366.2 MB)
18/07/31 13:40:30 INFO SparkContext: Invoking stop() from shutdown hook
18/07/31 13:40:30 INFO BlockManagerInfo: Removed broadcast_2_piece0 on sandbox-hdp.hortonworks.com:41237 in memory (size: 38.3 KB, free: 366.2 MB)
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 61
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 74
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 12
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 132
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 108
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 26
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 101
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 43
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 68
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 2
18/07/31 13:40:30 INFO BlockManagerInfo: Removed broadcast_5_piece0 on sandbox-hdp.hortonworks.com:42383 in memory (size: 7.6 KB, free: 366.2 MB)
18/07/31 13:40:30 INFO AbstractConnector: Stopped Spark@69e604af{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
18/07/31 13:40:30 INFO BlockManagerInfo: Removed broadcast_5_piece0 on sandbox-hdp.hortonworks.com:41237 in memory (size: 7.6 KB, free: 366.2 MB)
18/07/31 13:40:30 INFO SparkUI: Stopped Spark web UI at http://sandbox-hdp.hortonworks.com:4040
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 125
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 52
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 55
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 98
18/07/31 13:40:30 INFO ContextCleaner: Cleaned accumulator 120
18/07/31 13:40:30 INFO BlockManagerInfo: Removed broadcast_7_piece0 on sandbox-hdp.hortonworks.com:42383 in memory (size: 7.7 KB, free: 366.2 MB)
18/07/31 13:40:30 INFO BlockManagerInfo: Removed broadcast_7_piece0 on sandbox-hdp.hortonworks.com:41237 in memory (size: 7.7 KB, free: 366.2 MB)
18/07/31 13:40:30 INFO YarnClientSchedulerBackend: Interrupting monitor thread
18/07/31 13:40:30 INFO YarnClientSchedulerBackend: Shutting down all executors
18/07/31 13:40:30 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
18/07/31 13:40:30 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
18/07/31 13:40:30 INFO YarnClientSchedulerBackend: Stopped
18/07/31 13:40:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/07/31 13:40:30 INFO MemoryStore: MemoryStore cleared
18/07/31 13:40:30 INFO BlockManager: BlockManager stopped
18/07/31 13:40:30 INFO BlockManagerMaster: BlockManagerMaster stopped
18/07/31 13:40:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/07/31 13:40:30 INFO SparkContext: Successfully stopped SparkContext
18/07/31 13:40:30 INFO ShutdownHookManager: Shutdown hook called
18/07/31 13:40:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-8ce5739a-c601-4487-97ab-4af6ba965ef0
18/07/31 13:40:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-8ce5739a-c601-4487-97ab-4af6ba965ef0/pyspark-9e3f4575-c088-48cb-92cb-eec389f43202
18/07/31 13:40:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-458dfa01-8e7a-43ed-9981-871aded909f8
[root@sandbox-hdp raj_ops]# 

